{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWiShlYZPJspC8nJwnj7sb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarav-J/231801158_PODS/blob/main/Ex4(B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxQUOMtvK3kF",
        "outputId": "ec4644bd-6985-4a92-ba9d-80bdf467ca4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "STEP 3: Load and Prepare Dataset\n",
            "Original Dataset:\n",
            "                                                 Text\n",
            "0  Absolutely wonderful - silky and sexy and comf...\n",
            "1                 Love this dress! it's sooo pretty.\n",
            "2   I had to return it - the fit was just not right.\n",
            "3                Terrible quality. Do not recommend.\n",
            "4  Fast shipping and good packaging, but the prod...\n",
            "5  The color is not the same as shown in the pict... \n",
            "\n",
            "Cleaned Dataset (after removing missing):\n",
            "                                                 Text\n",
            "0  Absolutely wonderful - silky and sexy and comf...\n",
            "1                 Love this dress! it's sooo pretty.\n",
            "2   I had to return it - the fit was just not right.\n",
            "3                Terrible quality. Do not recommend.\n",
            "4  Fast shipping and good packaging, but the prod...\n",
            "5  The color is not the same as shown in the pict... \n",
            "\n",
            "STEP 4: Text Preprocessing using spaCy\n",
            "\n",
            "Original Text: Absolutely wonderful - silky and sexy and comfortable.\n",
            "a. Lowercased: absolutely wonderful - silky and sexy and comfortable.\n",
            "b. Tokens: ['absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable', '.']\n",
            "c. Alphabetic Tokens: ['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n",
            "d. Stopword Removed: ['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']\n",
            "e. Lemmatized Tokens: ['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']\n",
            "f. Final Cleaned String: absolutely wonderful silky sexy comfortable\n",
            "\n",
            "Original Text: Love this dress! it's sooo pretty.\n",
            "a. Lowercased: love this dress! it's sooo pretty.\n",
            "b. Tokens: ['love', 'this', 'dress', '!', 'it', \"'s\", 'sooo', 'pretty', '.']\n",
            "c. Alphabetic Tokens: ['love', 'this', 'dress', 'it', 'sooo', 'pretty']\n",
            "d. Stopword Removed: ['love', 'dress', 'sooo', 'pretty']\n",
            "e. Lemmatized Tokens: ['love', 'dress', 'sooo', 'pretty']\n",
            "f. Final Cleaned String: love dress sooo pretty\n",
            "\n",
            "Original Text: I had to return it - the fit was just not right.\n",
            "a. Lowercased: i had to return it - the fit was just not right.\n",
            "b. Tokens: ['i', 'had', 'to', 'return', 'it', '-', 'the', 'fit', 'was', 'just', 'not', 'right', '.']\n",
            "c. Alphabetic Tokens: ['i', 'had', 'to', 'return', 'it', 'the', 'fit', 'was', 'just', 'not', 'right']\n",
            "d. Stopword Removed: ['return', 'fit', 'right']\n",
            "e. Lemmatized Tokens: ['return', 'fit', 'right']\n",
            "f. Final Cleaned String: return fit right\n",
            "\n",
            "Original Text: Terrible quality. Do not recommend.\n",
            "a. Lowercased: terrible quality. do not recommend.\n",
            "b. Tokens: ['terrible', 'quality', '.', 'do', 'not', 'recommend', '.']\n",
            "c. Alphabetic Tokens: ['terrible', 'quality', 'do', 'not', 'recommend']\n",
            "d. Stopword Removed: ['terrible', 'quality', 'recommend']\n",
            "e. Lemmatized Tokens: ['terrible', 'quality', 'recommend']\n",
            "f. Final Cleaned String: terrible quality recommend\n",
            "\n",
            "Original Text: Fast shipping and good packaging, but the product is bad.\n",
            "a. Lowercased: fast shipping and good packaging, but the product is bad.\n",
            "b. Tokens: ['fast', 'shipping', 'and', 'good', 'packaging', ',', 'but', 'the', 'product', 'is', 'bad', '.']\n",
            "c. Alphabetic Tokens: ['fast', 'shipping', 'and', 'good', 'packaging', 'but', 'the', 'product', 'is', 'bad']\n",
            "d. Stopword Removed: ['fast', 'shipping', 'good', 'packaging', 'product', 'bad']\n",
            "e. Lemmatized Tokens: ['fast', 'shipping', 'good', 'packaging', 'product', 'bad']\n",
            "f. Final Cleaned String: fast shipping good packaging product bad\n",
            "\n",
            "Original Text: The color is not the same as shown in the picture.\n",
            "a. Lowercased: the color is not the same as shown in the picture.\n",
            "b. Tokens: ['the', 'color', 'is', 'not', 'the', 'same', 'as', 'shown', 'in', 'the', 'picture', '.']\n",
            "c. Alphabetic Tokens: ['the', 'color', 'is', 'not', 'the', 'same', 'as', 'shown', 'in', 'the', 'picture']\n",
            "d. Stopword Removed: ['color', 'shown', 'picture']\n",
            "e. Lemmatized Tokens: ['color', 'show', 'picture']\n",
            "f. Final Cleaned String: color show picture\n",
            "\n",
            "Final Cleaned Dataset:\n",
            "                                                 Text  \\\n",
            "0  Absolutely wonderful - silky and sexy and comf...   \n",
            "1                 Love this dress! it's sooo pretty.   \n",
            "2   I had to return it - the fit was just not right.   \n",
            "3                Terrible quality. Do not recommend.   \n",
            "4  Fast shipping and good packaging, but the prod...   \n",
            "5  The color is not the same as shown in the pict...   \n",
            "\n",
            "                                       cleaned  \n",
            "0  absolutely wonderful silky sexy comfortable  \n",
            "1                       love dress sooo pretty  \n",
            "2                             return fit right  \n",
            "3                   terrible quality recommend  \n",
            "4     fast shipping good packaging product bad  \n",
            "5                           color show picture   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy scikit-learn pandas --quiet\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nSTEP 3: Load and Prepare Dataset\")\n",
        "data = {\n",
        "    'Text': [\n",
        "        \"Absolutely wonderful - silky and sexy and comfortable.\",\n",
        "        \"Love this dress! it's sooo pretty.\",\n",
        "        \"I had to return it - the fit was just not right.\",\n",
        "        \"Terrible quality. Do not recommend.\",\n",
        "        \"Fast shipping and good packaging, but the product is bad.\",\n",
        "        \"The color is not the same as shown in the picture.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Dataset:\\n\", df, \"\\n\")\n",
        "\n",
        "df.dropna(subset=['Text'], inplace=True)\n",
        "\n",
        "df = df.head(1000)\n",
        "print(\"Cleaned Dataset (after removing missing):\\n\", df, \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"STEP 4: Text Preprocessing using spaCy\")\n",
        "\n",
        "def spacy_preprocess(text):\n",
        "    print(f\"\\nOriginal Text: {text}\")\n",
        "\n",
        "    text = text.lower()\n",
        "    print(\"a. Lowercased:\", text)\n",
        "\n",
        "\n",
        "    doc = nlp(text)\n",
        "    print(\"b. Tokens:\", [token.text for token in doc])\n",
        "\n",
        "\n",
        "    tokens = [token for token in doc if token.is_alpha]\n",
        "    print(\"c. Alphabetic Tokens:\", [t.text for t in tokens])\n",
        "\n",
        "\n",
        "    tokens = [token for token in tokens if not token.is_stop]\n",
        "    print(\"d. Stopword Removed:\", [t.text for t in tokens])\n",
        "\n",
        "\n",
        "    lemmas = [token.lemma_ for token in tokens]\n",
        "    print(\"e. Lemmatized Tokens:\", lemmas)\n",
        "\n",
        "\n",
        "    cleaned = ' '.join(lemmas)\n",
        "    print(\"f. Final Cleaned String:\", cleaned)\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "df['cleaned'] = df['Text'].apply(spacy_preprocess)\n",
        "\n",
        "print(\"\\nFinal Cleaned Dataset:\\n\", df[['Text', 'cleaned']], \"\\n\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}